---
title: MarkovChain Monte Carlo(MCMC) 기본 원리 설명
description: Dynamic Linear model의 기본적인 개념과 분포 개념 설명
author: starrypark
date: 2024-05-24 13:22:34 +0810
categories: [Statistics,Bayesian Analysis]
tags: [Statistics, MCMC, Bayesinan]
pin: true
math: true
mermaid: true
use_math: true
---

## 개요

베이지안 추론에서 가장 먼저 마주치는 난관은 사후분포(posterior distribution)를 직접 계산하기 어렵다는 점이다. 매개변수가 늘어날수록 적분은 손에 잡히지 않고, 계산은 사실상 불가능해진다.

이 문제를 해결하기 위한 방법이 **Markov Chain Monte Carlo(MCMC)** 다. 이름은 복잡해 보이지만 핵심은 단순하다. “직접 계산하지 말고, 샘플을 뽑아서 근사하자.”

---

## Gibbs Sampling: 조건부분포를 활용한 순차 샘플링

MCMC의 대표적 방법 중 하나가 **Gibbs 샘플링**이다. 매개변수가 여러 개인 경우, 한꺼번에 샘플링하기 어려우므로 **조건부분포(full conditional distribution)** 에서 하나씩 번갈아가며 샘플을 생성한다.

예를 들어 $\theta = (\theta\_1, \theta\_2, \dots, \theta\_p)$일 때,

* 먼저 \$\theta\_1\$을 다른 값들을 고정한 상태에서 뽑고,
* 이어서 갱신된 \$\theta\_1\$을 이용해 \$\theta\_2\$를 뽑고,
* 이런 과정을 반복하면 복잡한 사후분포에서 유효한 표본을 얻을 수 있다.

t-분포 prior와 Normal likelihood를 결합한 예제를 보면, 잠재변수(latent variable)를 하나 도입해 Gibbs 샘플링으로 손쉽게 사후분포를 근사할 수 있다. 적분으로는 풀리지 않는 문제가, 샘플링으로는 자연스럽게 해결되는 사례다.

---

## Metropolis-Hastings: 제안과 수락/거절

Metropolis-Hastings (MH) 알고리즘은 사후분포의 조건부분포를 알 수 없을 때 유용하게 쓰이는 MCMC 기법이다. 핵심 아이디어는 **제안분포(proposal distribution)** 로부터 후보값을 생성하고, 이를 현재 상태와 비교하여 일정 확률로 수용 여부를 결정하는 것이다.

---

### 알고리즘 절차

관심 있는 분포를 \$\pi(\theta)\$라 하고, 이를 직접 샘플링하기는 어렵다고 하자.

1. **제안 단계**
   현재 상태 \$\theta^{(t)}\$에서 제안분포 \$q(\theta'|\theta^{(t)})\$로부터 후보값 \$\theta'\$을 생성한다.

2. **수용 확률 계산**
   후보값을 채택할 확률은 다음과 같다.

   $$
   \alpha(\theta^{(t)}, \theta') = \min\left(1, \frac{\pi(\theta')\, q(\theta^{(t)}|\theta')}{\pi(\theta^{(t)})\, q(\theta'|\theta^{(t)})}\right)
   $$

   여기서 분모와 분자는 각각 현재 상태와 후보 상태가 주어진 조건에서 얼마나 “그럴듯한지”를 비교하는 비율이다.

3. **수용 또는 거부**
   \$u \sim \text{Uniform}(0,1)\$을 뽑아, \$u \leq \alpha(\theta^{(t)}, \theta')\$이면 \$\theta^{(t+1)} = \theta'\$로 이동한다.
   그렇지 않으면 \$\theta^{(t+1)} = \theta^{(t)}\$로 유지한다.

---

### 직관적 해석

이 방식은 마치 눈을 가린 채 산을 오르는 과정과 같다.

* **더 높은 지점**(posterior density가 더 큰 후보)은 항상 채택된다.
* **더 낮은 지점**은 일정 확률로 받아들여지므로, 전체 지형을 고르게 탐색할 수 있다.

이로써 단순히 최적값을 찾는 것이 아니라, 목표분포의 **모양 전체를 샘플링**하는 것이 가능하다.

---

### 제안분포의 역할

제안분포 \$q(\theta'|\theta)\$는 체인의 이동 성질을 결정한다. 특히 분산 크기는 다음과 같이 중요한 영향을 미친다.

* **분산이 너무 작을 경우**
  후보값이 현재 상태와 거의 다르지 않아 체인이 느리게 움직이고, 높은 자기상관을 보인다.

* **분산이 너무 클 경우**
  후보값이 극단적으로 튀어나와 대부분 거절되므로, 체인이 제자리에서 머무는 시간이 길어진다.

따라서 적절한 분산 조정이 필수적이다. 일반적으로 고차원 문제에서는 수용률이 약 20–30% 정도 되도록 튜닝하는 것이 권장된다.

---


## 실제 예제: COPD 데이터

실제 데이터에 MCMC를 적용해 보면 그 효용이 분명해진다. 영국 COPD(만성 폐쇄성 폐질환) 환자의 지역별 입원 데이터를 대상으로 다음과 같은 모형을 고려한다.

* 입원 건수 \$y\_i \sim \text{Poisson}(\theta\_i E\_i)\$
* 기대값 \$E\_i\$는 인구구조 보정값
* 상대위험도 \$\theta\_i \sim \text{Gamma}(a, b)\$

여기서 \$\theta\_i\$, \$a\$, \$b\$의 조건부분포를 정리한 후 Gibbs와 MH를 혼합하여 체인을 생성한다. 그 결과 지역별 상대위험도의 불확실성을 추정할 수 있으며, COPD 입원율이 높은 지역과 낮은 지역을 식별할 수 있다.

---

## MCMC 수렴 진단

MCMC의 결과를 해석하기 전에는 반드시 **수렴 여부**를 확인해야 한다.

* **Traceplot**: 체인의 궤적이 안정적으로 분포를 탐색하는지 시각적으로 확인.
* **Autocorrelation plot**: 자기상관이 지나치게 높으면 체인이 섞이지 않은 상태.
* **Running mean plot**: 표본 평균이 수렴하는지 점검.
* **Geweke test, Heidelberger-Welch test**: 체인의 앞부분과 뒷부분이 동일한 분포를 따르는지 검정.

충분히 오래 돌렸는지가 중요한 것이 아니라, 체인이 제대로 섞여서(stationary distribution에 도달) 의미 있는 표본을 제공하는지가 핵심이다.

---

## 맺음말

MCMC는 복잡한 적분 문제를 단순한 시뮬레이션 아이디어로 해결한다.

* Gibbs 샘플러는 조건부분포를 활용할 수 있을 때 강력하고,
* Metropolis-Hastings는 일반적인 상황에서도 적용 가능한 유연성을 가진다.
* 무엇보다 수렴 진단은 필수적이다.

오늘날 MCMC는 의료통계, 공간분석, 머신러닝 등 다양한 분야에서 핵심 도구로 자리 잡고 있다. 직접 계산하기 어려운 문제일수록, MCMC가 빛을 발한다.

